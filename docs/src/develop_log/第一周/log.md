# 第一周开发日志（1.25-1.31）

## 工作总结

- **基础知识学习** — 学习 NPU 原理、AI 模型运行原理、驱动在整个推理链条中的角色
- **RKNN Toolkit2 仿真验证** — 下载套件，阅读 demo 代码，在 x86 仿真器上跑通测例

---

## 基础知识学习

刚接到 NPU 驱动开发任务时，虽然听说过 NPU，但对它实际是什么、解决什么问题、工作原理、如何运行都不了解。花了一天时间系统学习了以下内容：

- **NPU 是什么** — 神经网络处理单元，专为矩阵运算和推理加速设计的硬件
- **AI 模型的本质** — 本质上是一个函数，是大量矩阵乘法配上激活函数。训练是拟合参数，推理是执行前向传播
- **模型格式与转换** — ONNX → RKNN 格式转换，量化，以及模型在 NPU 上的执行流程
- **驱动在整个链条中的角色** — 用户态库（`librknnrt.so`）通过 ioctl 与内核驱动通信，驱动负责任务调度、DMA 搬运、寄存器操作

---

## RKNN Toolkit2 套件与仿真验证

上 Rockchip 官网下载了 [rknn-toolkit2](https://github.com/airockchip/rknn-toolkit2) 套件，发现里面包含一个 **仿真器**，可以在 x86 主机上模拟 RKNPU 的部分功能。阅读了 demo 代码，理解了 RKNN 推理的基本 API 调用流程：

```
rknn_init()来初始化npu执行上下文 → rknn_inputs_set()读写npu寄存器设置输出输出参数 → rknn_run()写npu寄存器提醒npu开始工作和运行 → rknn_outputs_get()npu通过中断通知操作系统，用户库从约定位置读取结果 → rknn_destroy()销毁释放npu执行上下文
```

---
